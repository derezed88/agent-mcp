## tool-llm-clean-tool: llm_clean_tool tool definition

### llm_clean_tool(model: str, tool: str, arguments: str) → str
Delegate a single tool call to a target LLM model with no session context.

The target model receives only:
- The named tool's own definition as its system prompt
- Your arguments string as the user message

The server executes the tool call on behalf of the target model. Normal gates apply — the tool
must be pre-approved via !autogate or !autoAIdb, otherwise the call will auto-reject.
The target model synthesizes the tool result into a final text response, which is returned to you.

Parameters:
  model:     Model key name (e.g., "localModel"). Must have tool_call_available=YES.
             Use llm_list() to check. Local/free models are the primary use case.
  tool:      Exact tool name to delegate (e.g., "url_extract", "db_query", "ddgs_search").
  arguments: The request to pass to the target model. Be specific — include the URL, query,
             or SQL intent. This is the only user message the target model sees.

Returns: The target model's final text synthesis of the tool result.
         Only the synthesized text is returned — raw tool output does not enter your context.

Constraints:
- Single tool call only. The target model executes the tool once.
- Target model must have tool_call_available=YES. Use llm_list() to check.
- Same rate limit bucket as llm_clean_text (default: 3 calls per 20 seconds per session).
- Gates are honored normally. Pre-approve with !autogate or !autoAIdb before using.
- Returns a descriptive error string on failure (gate rejection, timeout, unknown tool/model).

When to use:
- You want a free/local model (localModel) to perform an extraction or search,
  saving token cost on the current paid session model.
- You want the tool result synthesized by the target model before it reaches your context,
  reducing noise in your conversation history.

Examples:
  llm_clean_tool(model="localModel", tool="url_extract",
                 arguments="Extract https://www.foxnews.com/world with query: world news today")

  llm_clean_tool(model="localModel", tool="ddgs_search",
                 arguments="Search for: latest AI model releases February 2026")

  llm_clean_tool(model="localModel", tool="db_query",
                 arguments="Query the sales table for total revenue by month in 2026")

Contrast with llm_clean_text:
  llm_clean_text — you gather data first, embed it in the prompt, target model only does text work.
  llm_clean_tool — server handles the tool call; target model only needs to direct and synthesize.
